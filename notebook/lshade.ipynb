{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "[3.22722294e-05 9.36677822e-05]\n",
      "0.00012594001161723043\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import cauchy\n",
    "\n",
    "def fitness(individual):\n",
    "    return np.sum(individual)\n",
    "\n",
    "def weighted_lehmar_mean(succeding_rates, individual_fitnesses, trial_fitnesses):\n",
    "    improvements = individual_fitnesses - trial_fitnesses\n",
    "    total_improvement = np.sum(improvements)\n",
    "    weights = improvements / total_improvement\n",
    "\n",
    "    lehmar_mean = np.sum(\n",
    "        weights * succeding_rates**2\n",
    "    ) / np.sum(weights * succeding_rates)\n",
    "\n",
    "    return lehmar_mean\n",
    "    \n",
    "\n",
    "problem_dimensionality = 2\n",
    "generation_number = 1\n",
    "initial_population_size = 100\n",
    "population_size = initial_population_size\n",
    "archive_size = initial_population_size\n",
    "archive = np.zeros((archive_size, problem_dimensionality))\n",
    "archive_fitnesses = np.empty(archive_size)\n",
    "archive_fitnesses.fill(np.nan)\n",
    "\n",
    "lower_boundary = 0 # per ora keep boundary fixed for all dimensions\n",
    "upper_boundary = 1 # per ora keep boundary fixed for all dimensions\n",
    "\n",
    "memory_size = 10 # H\n",
    "memory = np.zeros((memory_size, 2)) + 0.5\n",
    "\n",
    "p = 0.2\n",
    "\n",
    "MEMORY_MCR_INDEX = 0\n",
    "MEMORY_MMR_INDEX = 1\n",
    "\n",
    "previous_gen_population = np.random.uniform(\n",
    "    lower_boundary,\n",
    "    upper_boundary,\n",
    "    size=(initial_population_size, problem_dimensionality)\n",
    ")\n",
    "\n",
    "\n",
    "max_generations = 100\n",
    "\n",
    "crossing_rates = np.zeros(population_size)\n",
    "mutation_rates = np.zeros(population_size)\n",
    "\n",
    "previous_gen_individuals_fitnesses = np.array([fitness(individual) for individual in previous_gen_population])\n",
    "current_number_of_fitness_evaluations = population_size\n",
    "memory_index_to_update = 0\n",
    "\n",
    "max_number_fitness_evaluations = 1000\n",
    "min_number_of_individuals = 4\n",
    "\n",
    "best_individual_fitness_index = np.argmin(previous_gen_individuals_fitnesses)\n",
    "global_best_individual = previous_gen_population[best_individual_fitness_index]\n",
    "global_best_individual_fitness = previous_gen_individuals_fitnesses[best_individual_fitness_index]\n",
    "\n",
    "while (generation_number <= max_generations) and (current_number_of_fitness_evaluations < max_number_fitness_evaluations):\n",
    "    \n",
    "    succeding_crossover_rates = np.empty(population_size)\n",
    "    succeding_crossover_rates.fill(np.nan)  \n",
    "    succeding_mutation_rates = np.empty(population_size)\n",
    "    succeding_mutation_rates.fill(np.nan)\n",
    "    succeding_trials = np.empty((population_size, problem_dimensionality))\n",
    "    succeding_trial_fitnesses = np.empty(population_size)\n",
    "    succeding_trials_count = 0\n",
    "    trail_individuals = np.empty((population_size, problem_dimensionality))\n",
    "    trial_fitnesses = np.empty(population_size)\n",
    "    are_individuals_surpassed = np.zeros(population_size)\n",
    "    next_gen_individuals = previous_gen_population.copy()\n",
    "    next_gen_individuals_fitnesses = previous_gen_individuals_fitnesses.copy()\n",
    "\n",
    "    for individual_index in range(population_size):\n",
    "        memory_index = np.random.randint(0, memory_size)\n",
    "        if np.isnan(memory[memory_index, MEMORY_MCR_INDEX]):\n",
    "            crossing_rates[individual_index] = 0\n",
    "        else:\n",
    "            crossing_rates[individual_index] = np.clip(\n",
    "                np.random.normal(memory[memory_index, MEMORY_MCR_INDEX], 0.1),\n",
    "                0,\n",
    "                1.0\n",
    "            )\n",
    "\n",
    "        generated_mutation_rate = 0\n",
    "        while generated_mutation_rate <= 0:\n",
    "            generated_mutation_rate = np.clip(\n",
    "                cauchy.rvs(memory[memory_index, MEMORY_MMR_INDEX],0.1),\n",
    "                None,\n",
    "                1.0\n",
    "            )\n",
    "        mutation_rates[individual_index] = generated_mutation_rate\n",
    "\n",
    "        number_of_best_individuals = round(population_size * p)\n",
    "        random_best_individual_index = np.random.randint(\n",
    "            0, number_of_best_individuals\n",
    "        )\n",
    "\n",
    "        best_individuals_indices = np.argpartition(\n",
    "            previous_gen_individuals_fitnesses, number_of_best_individuals\n",
    "        )[:number_of_best_individuals]\n",
    "\n",
    "        best_individual = previous_gen_population[\n",
    "            best_individuals_indices[random_best_individual_index]\n",
    "        ]\n",
    "\n",
    "        number_individuals_in_archive = np.sum(~np.isnan(archive_fitnesses))\n",
    "        individual_indices_not_current = [\n",
    "            index for index in range(population_size + number_individuals_in_archive)\n",
    "            if index != individual_index\n",
    "        ]\n",
    "        random_individual_indices =np.random.choice(\n",
    "            individual_indices_not_current, 2, replace=False\n",
    "        )\n",
    "\n",
    "        random_individual_1 = (\n",
    "            previous_gen_population[random_individual_indices[0]]\n",
    "            if random_individual_indices[0] < population_size\n",
    "            else archive[random_individual_indices[0] - population_size]\n",
    "        )\n",
    "        random_individual_2 = (\n",
    "            previous_gen_population[random_individual_indices[1]]\n",
    "            if random_individual_indices[1] < population_size\n",
    "            else archive[random_individual_indices[1] - population_size]\n",
    "        )\n",
    "        current_individual = previous_gen_population[individual_index]\n",
    "\n",
    "        mutant = current_individual + mutation_rates[individual_index] * (\n",
    "            best_individual - current_individual\n",
    "        ) + mutation_rates[individual_index] * (\n",
    "            random_individual_1 - random_individual_2\n",
    "        )\n",
    "\n",
    "        for gene_index in range(problem_dimensionality):\n",
    "            if mutant[gene_index] < lower_boundary:\n",
    "                mutant[gene_index] = (\n",
    "                    lower_boundary + current_individual[gene_index]\n",
    "                ) / 2\n",
    "            elif mutant[gene_index] > upper_boundary:\n",
    "                mutant[gene_index] = (\n",
    "                    upper_boundary + current_individual[gene_index]\n",
    "                ) / 2\n",
    "\n",
    "        random_gene_index_to_mutate = np.random.randint(0, problem_dimensionality)\n",
    "        crossover_gene_index = np.random.rand(problem_dimensionality) < crossing_rates[individual_index]\n",
    "        crossover_gene_index[random_gene_index_to_mutate] = True\n",
    "\n",
    "        trail_individual = np.where(crossover_gene_index, mutant, current_individual)\n",
    "        trail_individuals[individual_index] = trail_individual\n",
    "        trial_fitnesses[individual_index] = fitness(trail_individual)\n",
    "        current_number_of_fitness_evaluations = current_number_of_fitness_evaluations + 1\n",
    "\n",
    "    for individual_index in range(population_size):\n",
    "\n",
    "        if (\n",
    "            trial_fitnesses[individual_index] <=\n",
    "            previous_gen_individuals_fitnesses[individual_index]\n",
    "        ):\n",
    "            next_gen_individuals[individual_index] = trail_individuals[individual_index]\n",
    "            next_gen_individuals_fitnesses[individual_index] = trial_fitnesses[individual_index]\n",
    "\n",
    "            if trial_fitnesses[individual_index] < previous_gen_individuals_fitnesses[individual_index]:\n",
    "                if number_individuals_in_archive < archive_size:\n",
    "                    archive[number_individuals_in_archive] = trail_individuals[individual_index]\n",
    "                    archive_fitnesses[number_individuals_in_archive] = trial_fitnesses[individual_index]\n",
    "                else:\n",
    "                    random_element_index = np.random.randint(0, archive_size)\n",
    "                    archive[random_element_index] = trail_individuals[individual_index]\n",
    "                    archive_fitnesses[random_element_index] = trial_fitnesses[individual_index]\n",
    "\n",
    "                succeding_mutation_rates[succeding_trials_count] = mutation_rates[individual_index]\n",
    "                succeding_crossover_rates[succeding_trials_count] = crossing_rates[individual_index]\n",
    "\n",
    "                succeding_trials[succeding_trials_count] = trail_individuals[individual_index]\n",
    "                succeding_trial_fitnesses[succeding_trials_count] = trial_fitnesses[individual_index]\n",
    "\n",
    "                are_individuals_surpassed[individual_index] = 1\n",
    "\n",
    "                succeding_trials_count += 1\n",
    "\n",
    "                if trial_fitnesses[individual_index] < global_best_individual_fitness:\n",
    "                    global_best_individual = trail_individuals[individual_index]\n",
    "                    global_best_individual_fitness = trial_fitnesses[individual_index]\n",
    "\n",
    "    if succeding_trials_count > 0:\n",
    "        if (\n",
    "            np.nanmax(succeding_mutation_rates) <= 0 or\n",
    "            np.isnan(memory[memory_index_to_update, MEMORY_MCR_INDEX])\n",
    "        ):\n",
    "            memory[memory_index_to_update, MEMORY_MCR_INDEX] = np.nan\n",
    "        else:\n",
    "            memory[memory_index_to_update, MEMORY_MCR_INDEX] = weighted_lehmar_mean(\n",
    "                succeding_crossover_rates[:succeding_trials_count],\n",
    "                previous_gen_individuals_fitnesses[are_individuals_surpassed == 1],\n",
    "                succeding_trial_fitnesses[:succeding_trials_count]\n",
    "            )\n",
    "        \n",
    "        memory[memory_index_to_update, MEMORY_MMR_INDEX] = weighted_lehmar_mean(\n",
    "            succeding_mutation_rates[:succeding_trials_count],\n",
    "            previous_gen_individuals_fitnesses[are_individuals_surpassed == 1],\n",
    "            succeding_trial_fitnesses[:succeding_trials_count]\n",
    "        )\n",
    "\n",
    "        memory_index_to_update = (memory_index_to_update + 1) % memory_size\n",
    "\n",
    "    next_gen_population_size = round(\n",
    "        (\n",
    "            (min_number_of_individuals - initial_population_size) /\n",
    "            max_number_fitness_evaluations\n",
    "        ) * current_number_of_fitness_evaluations + initial_population_size\n",
    "    )\n",
    "\n",
    "    if next_gen_population_size < population_size:\n",
    "        if next_gen_population_size < min_number_of_individuals:\n",
    "            next_gen_individuals = np.empty((0,2))\n",
    "            next_gen_individuals_fitnesses = np.empty(0)\n",
    "        else:\n",
    "            number_of_individuals_to_delete = population_size - next_gen_population_size\n",
    "            worst_individuals_indices = np.argpartition(\n",
    "                next_gen_individuals_fitnesses, -number_of_individuals_to_delete\n",
    "            )[:number_of_individuals_to_delete]\n",
    "\n",
    "            next_gen_individuals = np.delete(next_gen_individuals, worst_individuals_indices, axis=0)\n",
    "            next_gen_individuals_fitnesses = np.delete(\n",
    "                next_gen_individuals_fitnesses, worst_individuals_indices\n",
    "            )\n",
    "            population_size = next_gen_population_size\n",
    "    \n",
    "    previous_gen_population = next_gen_individuals\n",
    "    previous_gen_individuals_fitnesses = next_gen_individuals_fitnesses\n",
    "    print(generation_number)\n",
    "    generation_number = generation_number + 1\n",
    "\n",
    "\n",
    "print(global_best_individual)\n",
    "print(global_best_individual_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((0,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feedback_finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
